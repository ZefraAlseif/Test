{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RegressionModel_Wine.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "D5MXeNqXMXe6",
        "ElzmVsZeMsZ8",
        "TiUxZX-wB7KQ",
        "0cpTem6JeU0K",
        "8J8nqsr87Ose",
        "1jY8GDiKkMM9"
      ],
      "history_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZefraAlseif/MathProblems/blob/main/RegressionModel_Wine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adapting the original wine data to a regression model and classification model"
      ],
      "metadata": {
        "id": "D5MXeNqXMXe6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data as Numpy Arrays\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# This time we need to also import pandas\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "\n",
        "# Read in white wine data\n",
        "# Uses PANDAS (pd) to create a PANDAS DataFrame Object:\n",
        "white = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\", sep = ';')\n",
        "\n",
        "# Read in red wine data\n",
        "# Uses PANDAS (pd) to create a PANDAS DataFrame Object:\n",
        "red = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\", sep =';')\n",
        "\n",
        "red['type'] = 1\n",
        "white['type'] = 0\n",
        "\n",
        "wines = red.append(white, ignore_index = True)\n",
        "\n",
        "# Import SKLEARN\n",
        "import sklearn\n",
        "\n",
        "# Import `train_test_split` from `sklearn.model_selection`\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Specify the data -\n",
        "X1 = wines.iloc[:, 0:11]\n",
        "X2 = wines.iloc[:,12]\n",
        "X = pd.concat([X1,X2],axis = 1)\n",
        "\n",
        "y = np.ravel(wines.quality)\n",
        "\n",
        "# Splitting the data set for training and validating - Done with SKLEARN\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X,y, test_size = 0.25, random_state = 45)\n",
        "\n",
        "# Converting X_train & X_test DataFrame s to TF sensors\n",
        "# Will use NumPy, TF, & Keras after this\n",
        "# import tensorflow as tf\n",
        "\n",
        "Xtrain = X_train.to_numpy()\n",
        "X_valid = X_valid.to_numpy()\n",
        "\n",
        "X_valid\n",
        "# In reality:\n",
        "# [1] ALL THE Xtrain patterns (with their y_train targets)\n",
        "# will be used for TRAINING ([TR]), as Xtrain & y_train\n",
        "# [2] MOST OF THE X_valid patterns (and their y_valid targets)\n",
        "# will be used for VALIDATION ([TT]), as X_val & y_val\n",
        "# BUT WE WILL SET ASIDE THE LAST 10 for \"testing\" ([TS])\n",
        "# as X_tst & y_tst\n",
        "\n",
        "# Retain the first 1615 patterns for validation ([TT])\n",
        "Xval = X_valid[:1615]\n",
        "Xval.shape\n",
        "\n",
        "# and now set aside the last 10 for test\n",
        "Xtst = X_valid[1615:]\n",
        "Xtst.shape\n",
        "\n",
        "# Same for the corresponding targets\n",
        "# Retain the first 1615 for validation ([TT])\n",
        "y_val = y_valid[:1615]\n",
        "y_val.shape\n",
        "\n",
        "y_tst = y_valid[1615:]\n",
        "y_tst.shape \n",
        "y_tst\n",
        "\n",
        "# Now, in addition, create the targets as one-hot-encoded 4 quality levels\n",
        "# We will track these few targets through the conversion process\n",
        "y_train[272:283]\n",
        "\n",
        "# Function create rank-1 arrays where 3,4,5,6,7,8,9 are mapped to 1 or 2 or 3 or 4 \n",
        "def to_4cs(x):\n",
        "  lx = len(x)\n",
        "  results = np.zeros(lx)\n",
        "  for i in range(lx):\n",
        "    # print(\"start\")\n",
        "    xa = x[i];\n",
        "    if xa <= 3:\n",
        "      results[i] = 1\n",
        "    elif xa <= 6:\n",
        "      results[i] = 2\n",
        "    elif xa <= 8:\n",
        "      results[i] = 3\n",
        "    else:\n",
        "      results[i] = 4\n",
        "    # results [i, label] = 1\n",
        "  results = results.astype(int)\n",
        "  return results\n",
        "\n",
        "train_labels = to_4cs(y_train)\n",
        "val_labels = to_4cs(y_val)\n",
        "tst_labels = to_4cs(y_tst)\n",
        "\n",
        "# Let's verify that the training targets that we are tracking \n",
        "# were converted to levels (1 = BAD; 2 = Medium; 3 = GOOD; 4- Excellent) correctly:\n",
        "train_labels[272:283]\n",
        "\n",
        "# Now, one shot encoding of all 3 target arrays\n",
        "# define a function to do the \n",
        "\n",
        "def to_one_hot(labels, dimension = 4):\n",
        "  results = np.zeros((len(labels), dimension))\n",
        "  for i, label in enumerate(labels-1):\n",
        "    results[i, label] = 1.\n",
        "  return results\n",
        "\n",
        "one_hot_train_labels = to_one_hot(train_labels)\n",
        "one_hot_val_labels = to_one_hot(val_labels)\n",
        "one_hot_tst_labels = to_one_hot(tst_labels)\n",
        "\n",
        "#Let's verify that the training targets we have tracked were\n",
        "# one-hot encoded correctly\n",
        "Xtrain.shape\n",
        "\n",
        "# SO, AFTER EXECUTING THIS CELL, YOU WILL HAVE:\n",
        "# FOR TRAINING:\n",
        "# Xtrain (4872, 12)...y_train (4872,)...train_labels(4872,)....one_hot_train_labels (4872,4)\n",
        "# FOR VALIDATING:\n",
        "# Xval (1615, 12)...y_val (1615,)...val_labels(1615,)...one_hot_val_labels (1615,4)\n",
        "# FOR TESTING:\n",
        "# Xtst (10, 12)...y_tst (10,)...tst_labels(10,)... one_hot_tst_labels (10,4)\n",
        "# PLEASE DO NOT CHANGE THE NAMES OF THESE VARIABLES (So that instructor can use them)\n"
      ],
      "metadata": {
        "id": "RALOila3bW_c",
        "cellView": "code",
        "outputId": "7fed9921-13f9-4740-87f3-be0af85eb85c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4872, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II.1 Regression Model 1 (regmodl1)"
      ],
      "metadata": {
        "id": "ElzmVsZeMsZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.engine.input_layer import Input\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def build_regmodl1():\n",
        "  regmodl1 = keras.Sequential(\n",
        "      [\n",
        "        layers.Dense(5, activation = 'relu'),\n",
        "        layers.Dense(1)\n",
        "      ]\n",
        ")\n",
        "  regmodl1.compile(optimizer = \"rmsprop\", loss = \"mse\", metrics = [\"mae\"])\n",
        "  return regmodl1\n",
        "\n",
        "regmodl1 = build_regmodl1()\n",
        "history_regmodl1 = regmodl1.fit(x = Xtrain,y = train_labels, batch_size = 32, epochs = 50, verbose = 2, validation_data = (Xval,val_labels), validation_freq = 1)\n",
        "\n",
        "regmodl1.summary()"
      ],
      "metadata": {
        "id": "JV7YqcIrM2Op",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7d51585-d963-4abe-c4ec-29ff223206b4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "153/153 - 1s - loss: 147.0975 - mae: 7.2942 - val_loss: 2.7238 - val_mae: 1.2556 - 857ms/epoch - 6ms/step\n",
            "Epoch 2/50\n",
            "153/153 - 0s - loss: 0.8862 - mae: 0.6733 - val_loss: 0.3907 - val_mae: 0.4613 - 265ms/epoch - 2ms/step\n",
            "Epoch 3/50\n",
            "153/153 - 0s - loss: 0.3873 - mae: 0.4822 - val_loss: 0.6410 - val_mae: 0.6522 - 265ms/epoch - 2ms/step\n",
            "Epoch 4/50\n",
            "153/153 - 0s - loss: 0.3462 - mae: 0.4571 - val_loss: 0.3002 - val_mae: 0.4233 - 267ms/epoch - 2ms/step\n",
            "Epoch 5/50\n",
            "153/153 - 0s - loss: 0.3101 - mae: 0.4341 - val_loss: 0.3521 - val_mae: 0.4765 - 271ms/epoch - 2ms/step\n",
            "Epoch 6/50\n",
            "153/153 - 0s - loss: 0.2910 - mae: 0.4226 - val_loss: 0.2537 - val_mae: 0.3835 - 270ms/epoch - 2ms/step\n",
            "Epoch 7/50\n",
            "153/153 - 0s - loss: 0.2768 - mae: 0.4101 - val_loss: 0.2564 - val_mae: 0.3695 - 271ms/epoch - 2ms/step\n",
            "Epoch 8/50\n",
            "153/153 - 0s - loss: 0.2672 - mae: 0.3991 - val_loss: 0.2872 - val_mae: 0.4365 - 346ms/epoch - 2ms/step\n",
            "Epoch 9/50\n",
            "153/153 - 0s - loss: 0.2552 - mae: 0.3933 - val_loss: 0.2741 - val_mae: 0.4239 - 288ms/epoch - 2ms/step\n",
            "Epoch 10/50\n",
            "153/153 - 0s - loss: 0.2471 - mae: 0.3843 - val_loss: 0.2030 - val_mae: 0.3288 - 257ms/epoch - 2ms/step\n",
            "Epoch 11/50\n",
            "153/153 - 0s - loss: 0.2495 - mae: 0.3866 - val_loss: 0.3356 - val_mae: 0.4452 - 280ms/epoch - 2ms/step\n",
            "Epoch 12/50\n",
            "153/153 - 0s - loss: 0.2396 - mae: 0.3796 - val_loss: 0.3001 - val_mae: 0.4590 - 285ms/epoch - 2ms/step\n",
            "Epoch 13/50\n",
            "153/153 - 0s - loss: 0.2352 - mae: 0.3765 - val_loss: 0.2894 - val_mae: 0.4472 - 269ms/epoch - 2ms/step\n",
            "Epoch 14/50\n",
            "153/153 - 0s - loss: 0.2307 - mae: 0.3725 - val_loss: 0.2861 - val_mae: 0.4031 - 272ms/epoch - 2ms/step\n",
            "Epoch 15/50\n",
            "153/153 - 0s - loss: 0.2308 - mae: 0.3749 - val_loss: 0.2241 - val_mae: 0.3406 - 291ms/epoch - 2ms/step\n",
            "Epoch 16/50\n",
            "153/153 - 0s - loss: 0.2293 - mae: 0.3753 - val_loss: 0.1747 - val_mae: 0.3137 - 277ms/epoch - 2ms/step\n",
            "Epoch 17/50\n",
            "153/153 - 0s - loss: 0.2195 - mae: 0.3656 - val_loss: 0.1732 - val_mae: 0.2988 - 276ms/epoch - 2ms/step\n",
            "Epoch 18/50\n",
            "153/153 - 0s - loss: 0.2219 - mae: 0.3681 - val_loss: 0.1799 - val_mae: 0.3339 - 268ms/epoch - 2ms/step\n",
            "Epoch 19/50\n",
            "153/153 - 0s - loss: 0.2181 - mae: 0.3627 - val_loss: 0.4142 - val_mae: 0.5470 - 283ms/epoch - 2ms/step\n",
            "Epoch 20/50\n",
            "153/153 - 0s - loss: 0.2217 - mae: 0.3634 - val_loss: 0.2423 - val_mae: 0.4178 - 261ms/epoch - 2ms/step\n",
            "Epoch 21/50\n",
            "153/153 - 0s - loss: 0.2220 - mae: 0.3636 - val_loss: 0.2708 - val_mae: 0.3912 - 266ms/epoch - 2ms/step\n",
            "Epoch 22/50\n",
            "153/153 - 0s - loss: 0.2173 - mae: 0.3664 - val_loss: 0.2604 - val_mae: 0.3801 - 255ms/epoch - 2ms/step\n",
            "Epoch 23/50\n",
            "153/153 - 0s - loss: 0.2129 - mae: 0.3587 - val_loss: 0.3582 - val_mae: 0.4666 - 276ms/epoch - 2ms/step\n",
            "Epoch 24/50\n",
            "153/153 - 0s - loss: 0.2046 - mae: 0.3528 - val_loss: 0.1914 - val_mae: 0.3087 - 268ms/epoch - 2ms/step\n",
            "Epoch 25/50\n",
            "153/153 - 0s - loss: 0.2131 - mae: 0.3628 - val_loss: 0.2267 - val_mae: 0.3458 - 266ms/epoch - 2ms/step\n",
            "Epoch 26/50\n",
            "153/153 - 0s - loss: 0.2080 - mae: 0.3559 - val_loss: 0.3434 - val_mae: 0.4565 - 349ms/epoch - 2ms/step\n",
            "Epoch 27/50\n",
            "153/153 - 0s - loss: 0.2089 - mae: 0.3565 - val_loss: 0.1969 - val_mae: 0.3124 - 271ms/epoch - 2ms/step\n",
            "Epoch 28/50\n",
            "153/153 - 0s - loss: 0.2037 - mae: 0.3538 - val_loss: 0.1670 - val_mae: 0.2838 - 260ms/epoch - 2ms/step\n",
            "Epoch 29/50\n",
            "153/153 - 0s - loss: 0.2079 - mae: 0.3540 - val_loss: 0.3175 - val_mae: 0.4323 - 267ms/epoch - 2ms/step\n",
            "Epoch 30/50\n",
            "153/153 - 0s - loss: 0.2046 - mae: 0.3497 - val_loss: 0.2045 - val_mae: 0.3884 - 278ms/epoch - 2ms/step\n",
            "Epoch 31/50\n",
            "153/153 - 0s - loss: 0.2059 - mae: 0.3478 - val_loss: 0.4316 - val_mae: 0.5644 - 255ms/epoch - 2ms/step\n",
            "Epoch 32/50\n",
            "153/153 - 0s - loss: 0.2069 - mae: 0.3514 - val_loss: 0.1985 - val_mae: 0.3851 - 272ms/epoch - 2ms/step\n",
            "Epoch 33/50\n",
            "153/153 - 0s - loss: 0.2105 - mae: 0.3576 - val_loss: 0.1690 - val_mae: 0.3410 - 267ms/epoch - 2ms/step\n",
            "Epoch 34/50\n",
            "153/153 - 0s - loss: 0.2033 - mae: 0.3492 - val_loss: 0.1587 - val_mae: 0.3142 - 287ms/epoch - 2ms/step\n",
            "Epoch 35/50\n",
            "153/153 - 0s - loss: 0.2017 - mae: 0.3538 - val_loss: 0.1570 - val_mae: 0.2795 - 253ms/epoch - 2ms/step\n",
            "Epoch 36/50\n",
            "153/153 - 0s - loss: 0.1992 - mae: 0.3490 - val_loss: 0.2608 - val_mae: 0.4467 - 272ms/epoch - 2ms/step\n",
            "Epoch 37/50\n",
            "153/153 - 0s - loss: 0.1973 - mae: 0.3475 - val_loss: 0.1670 - val_mae: 0.2814 - 273ms/epoch - 2ms/step\n",
            "Epoch 38/50\n",
            "153/153 - 0s - loss: 0.2011 - mae: 0.3510 - val_loss: 0.4164 - val_mae: 0.5152 - 262ms/epoch - 2ms/step\n",
            "Epoch 39/50\n",
            "153/153 - 0s - loss: 0.1963 - mae: 0.3482 - val_loss: 0.3809 - val_mae: 0.5323 - 269ms/epoch - 2ms/step\n",
            "Epoch 40/50\n",
            "153/153 - 0s - loss: 0.1998 - mae: 0.3462 - val_loss: 0.2457 - val_mae: 0.3623 - 263ms/epoch - 2ms/step\n",
            "Epoch 41/50\n",
            "153/153 - 0s - loss: 0.1965 - mae: 0.3464 - val_loss: 0.5119 - val_mae: 0.5829 - 280ms/epoch - 2ms/step\n",
            "Epoch 42/50\n",
            "153/153 - 0s - loss: 0.1968 - mae: 0.3431 - val_loss: 0.1575 - val_mae: 0.3241 - 268ms/epoch - 2ms/step\n",
            "Epoch 43/50\n",
            "153/153 - 0s - loss: 0.1994 - mae: 0.3508 - val_loss: 0.1823 - val_mae: 0.3705 - 284ms/epoch - 2ms/step\n",
            "Epoch 44/50\n",
            "153/153 - 0s - loss: 0.1955 - mae: 0.3446 - val_loss: 0.1521 - val_mae: 0.2776 - 258ms/epoch - 2ms/step\n",
            "Epoch 45/50\n",
            "153/153 - 0s - loss: 0.1986 - mae: 0.3475 - val_loss: 0.4705 - val_mae: 0.5531 - 280ms/epoch - 2ms/step\n",
            "Epoch 46/50\n",
            "153/153 - 0s - loss: 0.2031 - mae: 0.3480 - val_loss: 0.4222 - val_mae: 0.5158 - 264ms/epoch - 2ms/step\n",
            "Epoch 47/50\n",
            "153/153 - 0s - loss: 0.2015 - mae: 0.3495 - val_loss: 0.1657 - val_mae: 0.2804 - 260ms/epoch - 2ms/step\n",
            "Epoch 48/50\n",
            "153/153 - 0s - loss: 0.2030 - mae: 0.3495 - val_loss: 0.1502 - val_mae: 0.2987 - 259ms/epoch - 2ms/step\n",
            "Epoch 49/50\n",
            "153/153 - 0s - loss: 0.1947 - mae: 0.3445 - val_loss: 0.2028 - val_mae: 0.3177 - 279ms/epoch - 2ms/step\n",
            "Epoch 50/50\n",
            "153/153 - 0s - loss: 0.1974 - mae: 0.3462 - val_loss: 0.2847 - val_mae: 0.3993 - 266ms/epoch - 2ms/step\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_23 (Dense)            (None, 5)                 65        \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 71\n",
            "Trainable params: 71\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot of Regression Model 1 and Final Values\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TiUxZX-wB7KQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the validation and training loss\n",
        "plt.plot(range(1, len(history_regmodl1.history['val_loss']) + 1), history_regmodl1.history['val_loss'], 'go', label = \"Validation Loss\")\n",
        "plt.plot(range(1, len(history_regmodl1.history['loss']) + 1), history_regmodl1.history['loss'],label = \"Training Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# Final Values\n",
        "print(\"Final Training loss: \",history_regmodl1.history['loss'][-1],\"\\nFinal Training MAE: \", history_regmodl1.history['mae'][-1])\n",
        "print(\"Final Validation loss: \",history_regmodl1.history['val_loss'][-1],\"\\nFinal Validation MAE: \", history_regmodl1.history['val_mae'][-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Z3W6HHHKCAM1",
        "outputId": "a2179d0a-093f-4286-e0c9-e3cba06c5b25"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Training loss:  0.19736634194850922 \n",
            "Final Training MAE:  0.34623849391937256\n",
            "Final Validation loss:  0.28467121720314026 \n",
            "Final Validation MAE:  0.3992602229118347\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II.2 Regression Model 2 (regmodl2)"
      ],
      "metadata": {
        "id": "0cpTem6JeU0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.engine.input_layer import Input\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def build_regmodl2():\n",
        "  regmodl2 = keras.Sequential(\n",
        "      [\n",
        "        layers.Dense(12, activation = 'relu'),\n",
        "        layers.Dense(8, activation = 'relu'),\n",
        "        layers.Dense(5, activation = 'relu'),\n",
        "        layers.Dense(3, activation='relu'), \n",
        "        layers.Dense(1, activation='relu')\n",
        "      ]\n",
        "  )\n",
        "  regmodl2.compile(optimizer = \"rmsprop\", loss = \"mse\", metrics = [\"mae\"])\n",
        "  return regmodl2\n",
        "\n",
        "regmodl2 = build_regmodl2()\n",
        "history_regmodl2 = regmodl2.fit(x = Xtrain,y = train_labels, batch_size = 64, epochs = 100, verbose = 2, validation_data = (Xval,val_labels), validation_freq = 1)\n",
        "\n",
        "#regmodl2.summary()"
      ],
      "metadata": {
        "id": "-W7ZMCDkefiM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a333bc1d-4028-4a08-f48e-d99c737de775"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "77/77 - 1s - loss: 1.4326 - mae: 0.9937 - val_loss: 1.0008 - val_mae: 0.8238 - 1s/epoch - 15ms/step\n",
            "Epoch 2/100\n",
            "77/77 - 0s - loss: 0.8877 - mae: 0.7637 - val_loss: 0.7477 - val_mae: 0.7050 - 168ms/epoch - 2ms/step\n",
            "Epoch 3/100\n",
            "77/77 - 0s - loss: 0.6245 - mae: 0.6330 - val_loss: 0.4600 - val_mae: 0.5544 - 176ms/epoch - 2ms/step\n",
            "Epoch 4/100\n",
            "77/77 - 0s - loss: 0.3005 - mae: 0.4119 - val_loss: 0.1785 - val_mae: 0.2849 - 177ms/epoch - 2ms/step\n",
            "Epoch 5/100\n",
            "77/77 - 0s - loss: 0.1647 - mae: 0.2973 - val_loss: 0.1669 - val_mae: 0.3004 - 169ms/epoch - 2ms/step\n",
            "Epoch 6/100\n",
            "77/77 - 0s - loss: 0.1602 - mae: 0.2944 - val_loss: 0.1656 - val_mae: 0.3313 - 182ms/epoch - 2ms/step\n",
            "Epoch 7/100\n",
            "77/77 - 0s - loss: 0.1579 - mae: 0.2942 - val_loss: 0.1615 - val_mae: 0.3123 - 199ms/epoch - 3ms/step\n",
            "Epoch 8/100\n",
            "77/77 - 0s - loss: 0.1566 - mae: 0.2933 - val_loss: 0.1610 - val_mae: 0.3133 - 197ms/epoch - 3ms/step\n",
            "Epoch 9/100\n",
            "77/77 - 0s - loss: 0.1559 - mae: 0.2948 - val_loss: 0.1634 - val_mae: 0.2759 - 198ms/epoch - 3ms/step\n",
            "Epoch 10/100\n",
            "77/77 - 0s - loss: 0.1543 - mae: 0.2923 - val_loss: 0.1578 - val_mae: 0.3050 - 160ms/epoch - 2ms/step\n",
            "Epoch 11/100\n",
            "77/77 - 0s - loss: 0.1519 - mae: 0.2911 - val_loss: 0.1577 - val_mae: 0.3162 - 200ms/epoch - 3ms/step\n",
            "Epoch 12/100\n",
            "77/77 - 0s - loss: 0.1519 - mae: 0.2898 - val_loss: 0.1560 - val_mae: 0.3038 - 156ms/epoch - 2ms/step\n",
            "Epoch 13/100\n",
            "77/77 - 0s - loss: 0.1504 - mae: 0.2910 - val_loss: 0.1601 - val_mae: 0.2750 - 193ms/epoch - 3ms/step\n",
            "Epoch 14/100\n",
            "77/77 - 0s - loss: 0.1494 - mae: 0.2880 - val_loss: 0.2040 - val_mae: 0.2934 - 196ms/epoch - 3ms/step\n",
            "Epoch 15/100\n",
            "77/77 - 0s - loss: 0.1482 - mae: 0.2864 - val_loss: 0.1638 - val_mae: 0.3493 - 158ms/epoch - 2ms/step\n",
            "Epoch 16/100\n",
            "77/77 - 0s - loss: 0.1475 - mae: 0.2882 - val_loss: 0.1715 - val_mae: 0.3680 - 192ms/epoch - 2ms/step\n",
            "Epoch 17/100\n",
            "77/77 - 0s - loss: 0.1474 - mae: 0.2874 - val_loss: 0.1534 - val_mae: 0.2847 - 195ms/epoch - 3ms/step\n",
            "Epoch 18/100\n",
            "77/77 - 0s - loss: 0.1474 - mae: 0.2867 - val_loss: 0.1894 - val_mae: 0.2823 - 200ms/epoch - 3ms/step\n",
            "Epoch 19/100\n",
            "77/77 - 0s - loss: 0.1485 - mae: 0.2875 - val_loss: 0.1518 - val_mae: 0.2849 - 157ms/epoch - 2ms/step\n",
            "Epoch 20/100\n",
            "77/77 - 0s - loss: 0.1474 - mae: 0.2857 - val_loss: 0.1795 - val_mae: 0.2761 - 163ms/epoch - 2ms/step\n",
            "Epoch 21/100\n",
            "77/77 - 0s - loss: 0.1450 - mae: 0.2853 - val_loss: 0.2394 - val_mae: 0.4503 - 158ms/epoch - 2ms/step\n",
            "Epoch 22/100\n",
            "77/77 - 0s - loss: 0.1460 - mae: 0.2855 - val_loss: 0.1511 - val_mae: 0.2845 - 163ms/epoch - 2ms/step\n",
            "Epoch 23/100\n",
            "77/77 - 0s - loss: 0.1450 - mae: 0.2843 - val_loss: 0.1643 - val_mae: 0.3538 - 159ms/epoch - 2ms/step\n",
            "Epoch 24/100\n",
            "77/77 - 0s - loss: 0.1443 - mae: 0.2829 - val_loss: 0.2100 - val_mae: 0.4231 - 191ms/epoch - 2ms/step\n",
            "Epoch 25/100\n",
            "77/77 - 0s - loss: 0.1441 - mae: 0.2846 - val_loss: 0.1787 - val_mae: 0.3799 - 194ms/epoch - 3ms/step\n",
            "Epoch 26/100\n",
            "77/77 - 0s - loss: 0.1440 - mae: 0.2827 - val_loss: 0.1606 - val_mae: 0.2660 - 157ms/epoch - 2ms/step\n",
            "Epoch 27/100\n",
            "77/77 - 0s - loss: 0.1429 - mae: 0.2829 - val_loss: 0.1688 - val_mae: 0.2685 - 190ms/epoch - 2ms/step\n",
            "Epoch 28/100\n",
            "77/77 - 0s - loss: 0.1435 - mae: 0.2827 - val_loss: 0.1525 - val_mae: 0.2666 - 202ms/epoch - 3ms/step\n",
            "Epoch 29/100\n",
            "77/77 - 0s - loss: 0.1431 - mae: 0.2815 - val_loss: 0.1923 - val_mae: 0.2874 - 157ms/epoch - 2ms/step\n",
            "Epoch 30/100\n",
            "77/77 - 0s - loss: 0.1423 - mae: 0.2794 - val_loss: 0.1579 - val_mae: 0.2590 - 198ms/epoch - 3ms/step\n",
            "Epoch 31/100\n",
            "77/77 - 0s - loss: 0.1440 - mae: 0.2808 - val_loss: 0.2133 - val_mae: 0.4274 - 161ms/epoch - 2ms/step\n",
            "Epoch 32/100\n",
            "77/77 - 0s - loss: 0.1413 - mae: 0.2817 - val_loss: 0.2008 - val_mae: 0.4085 - 188ms/epoch - 2ms/step\n",
            "Epoch 33/100\n",
            "77/77 - 0s - loss: 0.1425 - mae: 0.2820 - val_loss: 0.1748 - val_mae: 0.2731 - 196ms/epoch - 3ms/step\n",
            "Epoch 34/100\n",
            "77/77 - 0s - loss: 0.1420 - mae: 0.2791 - val_loss: 0.2333 - val_mae: 0.3334 - 192ms/epoch - 2ms/step\n",
            "Epoch 35/100\n",
            "77/77 - 0s - loss: 0.1418 - mae: 0.2798 - val_loss: 0.1692 - val_mae: 0.2703 - 167ms/epoch - 2ms/step\n",
            "Epoch 36/100\n",
            "77/77 - 0s - loss: 0.1413 - mae: 0.2798 - val_loss: 0.1636 - val_mae: 0.3538 - 170ms/epoch - 2ms/step\n",
            "Epoch 37/100\n",
            "77/77 - 0s - loss: 0.1422 - mae: 0.2797 - val_loss: 0.1803 - val_mae: 0.3868 - 158ms/epoch - 2ms/step\n",
            "Epoch 38/100\n",
            "77/77 - 0s - loss: 0.1412 - mae: 0.2810 - val_loss: 0.1602 - val_mae: 0.3477 - 156ms/epoch - 2ms/step\n",
            "Epoch 39/100\n",
            "77/77 - 0s - loss: 0.1402 - mae: 0.2791 - val_loss: 0.1853 - val_mae: 0.2869 - 204ms/epoch - 3ms/step\n",
            "Epoch 40/100\n",
            "77/77 - 0s - loss: 0.1413 - mae: 0.2795 - val_loss: 0.1486 - val_mae: 0.3125 - 161ms/epoch - 2ms/step\n",
            "Epoch 41/100\n",
            "77/77 - 0s - loss: 0.1395 - mae: 0.2777 - val_loss: 0.1744 - val_mae: 0.3776 - 166ms/epoch - 2ms/step\n",
            "Epoch 42/100\n",
            "77/77 - 0s - loss: 0.1402 - mae: 0.2800 - val_loss: 0.1698 - val_mae: 0.2710 - 167ms/epoch - 2ms/step\n",
            "Epoch 43/100\n",
            "77/77 - 0s - loss: 0.1392 - mae: 0.2769 - val_loss: 0.1684 - val_mae: 0.2694 - 163ms/epoch - 2ms/step\n",
            "Epoch 44/100\n",
            "77/77 - 0s - loss: 0.1393 - mae: 0.2765 - val_loss: 0.1447 - val_mae: 0.2811 - 162ms/epoch - 2ms/step\n",
            "Epoch 45/100\n",
            "77/77 - 0s - loss: 0.1403 - mae: 0.2786 - val_loss: 0.2061 - val_mae: 0.4183 - 198ms/epoch - 3ms/step\n",
            "Epoch 46/100\n",
            "77/77 - 0s - loss: 0.1399 - mae: 0.2793 - val_loss: 0.1951 - val_mae: 0.4050 - 200ms/epoch - 3ms/step\n",
            "Epoch 47/100\n",
            "77/77 - 0s - loss: 0.1399 - mae: 0.2796 - val_loss: 0.1596 - val_mae: 0.3495 - 168ms/epoch - 2ms/step\n",
            "Epoch 48/100\n",
            "77/77 - 0s - loss: 0.1390 - mae: 0.2780 - val_loss: 0.1452 - val_mae: 0.2680 - 164ms/epoch - 2ms/step\n",
            "Epoch 49/100\n",
            "77/77 - 0s - loss: 0.1390 - mae: 0.2775 - val_loss: 0.2046 - val_mae: 0.4162 - 200ms/epoch - 3ms/step\n",
            "Epoch 50/100\n",
            "77/77 - 0s - loss: 0.1392 - mae: 0.2776 - val_loss: 0.1451 - val_mae: 0.3044 - 205ms/epoch - 3ms/step\n",
            "Epoch 51/100\n",
            "77/77 - 0s - loss: 0.1382 - mae: 0.2782 - val_loss: 0.1453 - val_mae: 0.2663 - 193ms/epoch - 3ms/step\n",
            "Epoch 52/100\n",
            "77/77 - 0s - loss: 0.1382 - mae: 0.2764 - val_loss: 0.1511 - val_mae: 0.2629 - 167ms/epoch - 2ms/step\n",
            "Epoch 53/100\n",
            "77/77 - 0s - loss: 0.1384 - mae: 0.2768 - val_loss: 0.1891 - val_mae: 0.3961 - 225ms/epoch - 3ms/step\n",
            "Epoch 54/100\n",
            "77/77 - 0s - loss: 0.1393 - mae: 0.2791 - val_loss: 0.1934 - val_mae: 0.2966 - 193ms/epoch - 3ms/step\n",
            "Epoch 55/100\n",
            "77/77 - 0s - loss: 0.1395 - mae: 0.2770 - val_loss: 0.1632 - val_mae: 0.2673 - 165ms/epoch - 2ms/step\n",
            "Epoch 56/100\n",
            "77/77 - 0s - loss: 0.1383 - mae: 0.2765 - val_loss: 0.1437 - val_mae: 0.2989 - 158ms/epoch - 2ms/step\n",
            "Epoch 57/100\n",
            "77/77 - 0s - loss: 0.1385 - mae: 0.2770 - val_loss: 0.2236 - val_mae: 0.4349 - 189ms/epoch - 2ms/step\n",
            "Epoch 58/100\n",
            "77/77 - 0s - loss: 0.1389 - mae: 0.2786 - val_loss: 0.1664 - val_mae: 0.3634 - 196ms/epoch - 3ms/step\n",
            "Epoch 59/100\n",
            "77/77 - 0s - loss: 0.1380 - mae: 0.2767 - val_loss: 0.1456 - val_mae: 0.2639 - 155ms/epoch - 2ms/step\n",
            "Epoch 60/100\n",
            "77/77 - 0s - loss: 0.1382 - mae: 0.2754 - val_loss: 0.1931 - val_mae: 0.4023 - 198ms/epoch - 3ms/step\n",
            "Epoch 61/100\n",
            "77/77 - 0s - loss: 0.1395 - mae: 0.2789 - val_loss: 0.1433 - val_mae: 0.3001 - 171ms/epoch - 2ms/step\n",
            "Epoch 62/100\n",
            "77/77 - 0s - loss: 0.1375 - mae: 0.2770 - val_loss: 0.1605 - val_mae: 0.2681 - 162ms/epoch - 2ms/step\n",
            "Epoch 63/100\n",
            "77/77 - 0s - loss: 0.1381 - mae: 0.2763 - val_loss: 0.1869 - val_mae: 0.2921 - 192ms/epoch - 2ms/step\n",
            "Epoch 64/100\n",
            "77/77 - 0s - loss: 0.1391 - mae: 0.2770 - val_loss: 0.1642 - val_mae: 0.2682 - 156ms/epoch - 2ms/step\n",
            "Epoch 65/100\n",
            "77/77 - 0s - loss: 0.1380 - mae: 0.2769 - val_loss: 0.1683 - val_mae: 0.2729 - 158ms/epoch - 2ms/step\n",
            "Epoch 66/100\n",
            "77/77 - 0s - loss: 0.1385 - mae: 0.2754 - val_loss: 0.1654 - val_mae: 0.3616 - 195ms/epoch - 3ms/step\n",
            "Epoch 67/100\n",
            "77/77 - 0s - loss: 0.1388 - mae: 0.2772 - val_loss: 0.1929 - val_mae: 0.2988 - 202ms/epoch - 3ms/step\n",
            "Epoch 68/100\n",
            "77/77 - 0s - loss: 0.1379 - mae: 0.2751 - val_loss: 0.1989 - val_mae: 0.4093 - 158ms/epoch - 2ms/step\n",
            "Epoch 69/100\n",
            "77/77 - 0s - loss: 0.1381 - mae: 0.2774 - val_loss: 0.1422 - val_mae: 0.2867 - 202ms/epoch - 3ms/step\n",
            "Epoch 70/100\n",
            "77/77 - 0s - loss: 0.1375 - mae: 0.2767 - val_loss: 0.1501 - val_mae: 0.2609 - 194ms/epoch - 3ms/step\n",
            "Epoch 71/100\n",
            "77/77 - 0s - loss: 0.1376 - mae: 0.2760 - val_loss: 0.1520 - val_mae: 0.2609 - 162ms/epoch - 2ms/step\n",
            "Epoch 72/100\n",
            "77/77 - 0s - loss: 0.1376 - mae: 0.2764 - val_loss: 0.1439 - val_mae: 0.3043 - 166ms/epoch - 2ms/step\n",
            "Epoch 73/100\n",
            "77/77 - 0s - loss: 0.1379 - mae: 0.2760 - val_loss: 0.1658 - val_mae: 0.3613 - 199ms/epoch - 3ms/step\n",
            "Epoch 74/100\n",
            "77/77 - 0s - loss: 0.1381 - mae: 0.2772 - val_loss: 0.1418 - val_mae: 0.2817 - 165ms/epoch - 2ms/step\n",
            "Epoch 75/100\n",
            "77/77 - 0s - loss: 0.1372 - mae: 0.2756 - val_loss: 0.1641 - val_mae: 0.2755 - 198ms/epoch - 3ms/step\n",
            "Epoch 76/100\n",
            "77/77 - 0s - loss: 0.1385 - mae: 0.2762 - val_loss: 0.1591 - val_mae: 0.3498 - 193ms/epoch - 3ms/step\n",
            "Epoch 77/100\n",
            "77/77 - 0s - loss: 0.1375 - mae: 0.2777 - val_loss: 0.1625 - val_mae: 0.2666 - 168ms/epoch - 2ms/step\n",
            "Epoch 78/100\n",
            "77/77 - 0s - loss: 0.1375 - mae: 0.2765 - val_loss: 0.1417 - val_mae: 0.2840 - 193ms/epoch - 3ms/step\n",
            "Epoch 79/100\n",
            "77/77 - 0s - loss: 0.1385 - mae: 0.2769 - val_loss: 0.1682 - val_mae: 0.2773 - 201ms/epoch - 3ms/step\n",
            "Epoch 80/100\n",
            "77/77 - 0s - loss: 0.1369 - mae: 0.2750 - val_loss: 0.1426 - val_mae: 0.2971 - 211ms/epoch - 3ms/step\n",
            "Epoch 81/100\n",
            "77/77 - 0s - loss: 0.1361 - mae: 0.2743 - val_loss: 0.1717 - val_mae: 0.2783 - 195ms/epoch - 3ms/step\n",
            "Epoch 82/100\n",
            "77/77 - 0s - loss: 0.1370 - mae: 0.2757 - val_loss: 0.1727 - val_mae: 0.2797 - 155ms/epoch - 2ms/step\n",
            "Epoch 83/100\n",
            "77/77 - 0s - loss: 0.1377 - mae: 0.2759 - val_loss: 0.1475 - val_mae: 0.2605 - 202ms/epoch - 3ms/step\n",
            "Epoch 84/100\n",
            "77/77 - 0s - loss: 0.1360 - mae: 0.2737 - val_loss: 0.2082 - val_mae: 0.4192 - 164ms/epoch - 2ms/step\n",
            "Epoch 85/100\n",
            "77/77 - 0s - loss: 0.1375 - mae: 0.2765 - val_loss: 0.1933 - val_mae: 0.4014 - 164ms/epoch - 2ms/step\n",
            "Epoch 86/100\n",
            "77/77 - 0s - loss: 0.1371 - mae: 0.2757 - val_loss: 0.2946 - val_mae: 0.4927 - 190ms/epoch - 2ms/step\n",
            "Epoch 87/100\n",
            "77/77 - 0s - loss: 0.1391 - mae: 0.2795 - val_loss: 0.1488 - val_mae: 0.3246 - 166ms/epoch - 2ms/step\n",
            "Epoch 88/100\n",
            "77/77 - 0s - loss: 0.1366 - mae: 0.2765 - val_loss: 0.1661 - val_mae: 0.3619 - 188ms/epoch - 2ms/step\n",
            "Epoch 89/100\n",
            "77/77 - 0s - loss: 0.1369 - mae: 0.2762 - val_loss: 0.1910 - val_mae: 0.2977 - 190ms/epoch - 2ms/step\n",
            "Epoch 90/100\n",
            "77/77 - 0s - loss: 0.1375 - mae: 0.2761 - val_loss: 0.1462 - val_mae: 0.3161 - 200ms/epoch - 3ms/step\n",
            "Epoch 91/100\n",
            "77/77 - 0s - loss: 0.1362 - mae: 0.2760 - val_loss: 0.1425 - val_mae: 0.2709 - 168ms/epoch - 2ms/step\n",
            "Epoch 92/100\n",
            "77/77 - 0s - loss: 0.1364 - mae: 0.2754 - val_loss: 0.1426 - val_mae: 0.2699 - 192ms/epoch - 2ms/step\n",
            "Epoch 93/100\n",
            "77/77 - 0s - loss: 0.1367 - mae: 0.2756 - val_loss: 0.1413 - val_mae: 0.2891 - 166ms/epoch - 2ms/step\n",
            "Epoch 94/100\n",
            "77/77 - 0s - loss: 0.1375 - mae: 0.2773 - val_loss: 0.2270 - val_mae: 0.3378 - 171ms/epoch - 2ms/step\n",
            "Epoch 95/100\n",
            "77/77 - 0s - loss: 0.1376 - mae: 0.2762 - val_loss: 0.1471 - val_mae: 0.3197 - 157ms/epoch - 2ms/step\n",
            "Epoch 96/100\n",
            "77/77 - 0s - loss: 0.1370 - mae: 0.2768 - val_loss: 0.1431 - val_mae: 0.3030 - 190ms/epoch - 2ms/step\n",
            "Epoch 97/100\n",
            "77/77 - 0s - loss: 0.1369 - mae: 0.2769 - val_loss: 0.1427 - val_mae: 0.3000 - 160ms/epoch - 2ms/step\n",
            "Epoch 98/100\n",
            "77/77 - 0s - loss: 0.1367 - mae: 0.2757 - val_loss: 0.1688 - val_mae: 0.2776 - 192ms/epoch - 2ms/step\n",
            "Epoch 99/100\n",
            "77/77 - 0s - loss: 0.1375 - mae: 0.2761 - val_loss: 0.1736 - val_mae: 0.2827 - 169ms/epoch - 2ms/step\n",
            "Epoch 100/100\n",
            "77/77 - 0s - loss: 0.1375 - mae: 0.2771 - val_loss: 0.1446 - val_mae: 0.2645 - 168ms/epoch - 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot of Regression Model 2"
      ],
      "metadata": {
        "id": "8J8nqsr87Ose"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the validation and training loss\n",
        "plt.plot(range(1, len(history_regmodl2.history['val_loss']) + 1), history_regmodl2.history['val_loss'], 'go',label = \"Validation Loss\")\n",
        "plt.plot(range(1, len(history_regmodl2.history['loss']) + 1), history_regmodl2.history['loss'], label = \"Training Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# Final Values\n",
        "print(\"Final Training loss: \",history_regmodl2.history['loss'][-1],\"\\nFinal Training MAE: \", history_regmodl2.history['mae'][-1])\n",
        "print(\"Final Validation loss: \",history_regmodl2.history['val_loss'][-1],\"\\nFinal Validation MAE: \", history_regmodl2.history['val_mae'][-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "mBpEEGO68K5-",
        "outputId": "3429e60b-38ac-46a1-b127-bd4e096f50dc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Training loss:  0.13752268254756927 \n",
            "Final Training MAE:  0.27712732553482056\n",
            "Final Validation loss:  0.14458781480789185 \n",
            "Final Validation MAE:  0.2644997537136078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II.3 Regression Model 3 (regmodl3)"
      ],
      "metadata": {
        "id": "1jY8GDiKkMM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.engine.input_layer import Input\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def build_regmodl3():\n",
        "  regmodl3 = keras.Sequential(\n",
        "      [\n",
        "        layers.Dense(20, activation = 'relu'),\n",
        "        layers.Dense(15, activation = 'relu'),\n",
        "        layers.Dense(10, activation = 'relu'),\n",
        "        layers.Dense(1, activation = 'relu')\n",
        "      ]\n",
        "  )\n",
        "  regmodl3.compile(optimizer = \"rmsprop\", loss = \"mse\", metrics = [\"mae\"])\n",
        "  return regmodl3\n",
        "\n",
        "regmodl3 = build_regmodl3()\n",
        "history_regmodl3 = regmodl3.fit(x = Xtrain,y = train_labels, batch_size = 128, epochs = 50, verbose = 2, validation_data = (Xval,val_labels), validation_freq = 1)\n",
        "\n",
        "regmodl3.summary()"
      ],
      "metadata": {
        "id": "Al0_nQ_6kTQp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f780ecca-bb0e-4ec4-c1fa-8dca2c571274"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "39/39 - 1s - loss: 8.6722 - mae: 1.7461 - val_loss: 0.7207 - val_mae: 0.6625 - 945ms/epoch - 24ms/step\n",
            "Epoch 2/50\n",
            "39/39 - 0s - loss: 0.3858 - mae: 0.4780 - val_loss: 0.2675 - val_mae: 0.4201 - 107ms/epoch - 3ms/step\n",
            "Epoch 3/50\n",
            "39/39 - 0s - loss: 0.2970 - mae: 0.4216 - val_loss: 0.2131 - val_mae: 0.3777 - 103ms/epoch - 3ms/step\n",
            "Epoch 4/50\n",
            "39/39 - 0s - loss: 0.2678 - mae: 0.3995 - val_loss: 0.1871 - val_mae: 0.3284 - 102ms/epoch - 3ms/step\n",
            "Epoch 5/50\n",
            "39/39 - 0s - loss: 0.2518 - mae: 0.3938 - val_loss: 0.3704 - val_mae: 0.4634 - 109ms/epoch - 3ms/step\n",
            "Epoch 6/50\n",
            "39/39 - 0s - loss: 0.2453 - mae: 0.3871 - val_loss: 0.1935 - val_mae: 0.3784 - 101ms/epoch - 3ms/step\n",
            "Epoch 7/50\n",
            "39/39 - 0s - loss: 0.2311 - mae: 0.3804 - val_loss: 0.3833 - val_mae: 0.4758 - 103ms/epoch - 3ms/step\n",
            "Epoch 8/50\n",
            "39/39 - 0s - loss: 0.2326 - mae: 0.3771 - val_loss: 0.2311 - val_mae: 0.3372 - 108ms/epoch - 3ms/step\n",
            "Epoch 9/50\n",
            "39/39 - 0s - loss: 0.2256 - mae: 0.3710 - val_loss: 0.2106 - val_mae: 0.4097 - 98ms/epoch - 3ms/step\n",
            "Epoch 10/50\n",
            "39/39 - 0s - loss: 0.2433 - mae: 0.3859 - val_loss: 0.1722 - val_mae: 0.2895 - 112ms/epoch - 3ms/step\n",
            "Epoch 11/50\n",
            "39/39 - 0s - loss: 0.2143 - mae: 0.3594 - val_loss: 0.2048 - val_mae: 0.4020 - 108ms/epoch - 3ms/step\n",
            "Epoch 12/50\n",
            "39/39 - 0s - loss: 0.2225 - mae: 0.3697 - val_loss: 0.1852 - val_mae: 0.2949 - 101ms/epoch - 3ms/step\n",
            "Epoch 13/50\n",
            "39/39 - 0s - loss: 0.2263 - mae: 0.3772 - val_loss: 0.2166 - val_mae: 0.4168 - 107ms/epoch - 3ms/step\n",
            "Epoch 14/50\n",
            "39/39 - 0s - loss: 0.2132 - mae: 0.3654 - val_loss: 0.1693 - val_mae: 0.2882 - 114ms/epoch - 3ms/step\n",
            "Epoch 15/50\n",
            "39/39 - 0s - loss: 0.2092 - mae: 0.3598 - val_loss: 0.1994 - val_mae: 0.3942 - 111ms/epoch - 3ms/step\n",
            "Epoch 16/50\n",
            "39/39 - 0s - loss: 0.2108 - mae: 0.3585 - val_loss: 0.2138 - val_mae: 0.4165 - 104ms/epoch - 3ms/step\n",
            "Epoch 17/50\n",
            "39/39 - 0s - loss: 0.1982 - mae: 0.3463 - val_loss: 0.6488 - val_mae: 0.6678 - 103ms/epoch - 3ms/step\n",
            "Epoch 18/50\n",
            "39/39 - 0s - loss: 0.2112 - mae: 0.3526 - val_loss: 0.1980 - val_mae: 0.3053 - 96ms/epoch - 2ms/step\n",
            "Epoch 19/50\n",
            "39/39 - 0s - loss: 0.2085 - mae: 0.3557 - val_loss: 0.1684 - val_mae: 0.2802 - 99ms/epoch - 3ms/step\n",
            "Epoch 20/50\n",
            "39/39 - 0s - loss: 0.2004 - mae: 0.3447 - val_loss: 0.1816 - val_mae: 0.2915 - 99ms/epoch - 3ms/step\n",
            "Epoch 21/50\n",
            "39/39 - 0s - loss: 0.1939 - mae: 0.3322 - val_loss: 0.5600 - val_mae: 0.6092 - 101ms/epoch - 3ms/step\n",
            "Epoch 22/50\n",
            "39/39 - 0s - loss: 0.2016 - mae: 0.3505 - val_loss: 0.1588 - val_mae: 0.2866 - 99ms/epoch - 3ms/step\n",
            "Epoch 23/50\n",
            "39/39 - 0s - loss: 0.1926 - mae: 0.3420 - val_loss: 0.2591 - val_mae: 0.3693 - 104ms/epoch - 3ms/step\n",
            "Epoch 24/50\n",
            "39/39 - 0s - loss: 0.1968 - mae: 0.3493 - val_loss: 0.2253 - val_mae: 0.3339 - 105ms/epoch - 3ms/step\n",
            "Epoch 25/50\n",
            "39/39 - 0s - loss: 0.1953 - mae: 0.3463 - val_loss: 0.2247 - val_mae: 0.3316 - 100ms/epoch - 3ms/step\n",
            "Epoch 26/50\n",
            "39/39 - 0s - loss: 0.1889 - mae: 0.3425 - val_loss: 0.2490 - val_mae: 0.3567 - 100ms/epoch - 3ms/step\n",
            "Epoch 27/50\n",
            "39/39 - 0s - loss: 0.1879 - mae: 0.3406 - val_loss: 0.4429 - val_mae: 0.5723 - 99ms/epoch - 3ms/step\n",
            "Epoch 28/50\n",
            "39/39 - 0s - loss: 0.1847 - mae: 0.3305 - val_loss: 0.3494 - val_mae: 0.4525 - 119ms/epoch - 3ms/step\n",
            "Epoch 29/50\n",
            "39/39 - 0s - loss: 0.1852 - mae: 0.3309 - val_loss: 0.1684 - val_mae: 0.3522 - 116ms/epoch - 3ms/step\n",
            "Epoch 30/50\n",
            "39/39 - 0s - loss: 0.1863 - mae: 0.3355 - val_loss: 0.2299 - val_mae: 0.3364 - 106ms/epoch - 3ms/step\n",
            "Epoch 31/50\n",
            "39/39 - 0s - loss: 0.1913 - mae: 0.3436 - val_loss: 0.1665 - val_mae: 0.2816 - 140ms/epoch - 4ms/step\n",
            "Epoch 32/50\n",
            "39/39 - 0s - loss: 0.1762 - mae: 0.3210 - val_loss: 0.4391 - val_mae: 0.5753 - 113ms/epoch - 3ms/step\n",
            "Epoch 33/50\n",
            "39/39 - 0s - loss: 0.1818 - mae: 0.3267 - val_loss: 0.3847 - val_mae: 0.4823 - 99ms/epoch - 3ms/step\n",
            "Epoch 34/50\n",
            "39/39 - 0s - loss: 0.1778 - mae: 0.3225 - val_loss: 0.1988 - val_mae: 0.4036 - 100ms/epoch - 3ms/step\n",
            "Epoch 35/50\n",
            "39/39 - 0s - loss: 0.1777 - mae: 0.3302 - val_loss: 0.3799 - val_mae: 0.5331 - 100ms/epoch - 3ms/step\n",
            "Epoch 36/50\n",
            "39/39 - 0s - loss: 0.1880 - mae: 0.3363 - val_loss: 0.1982 - val_mae: 0.3085 - 100ms/epoch - 3ms/step\n",
            "Epoch 37/50\n",
            "39/39 - 0s - loss: 0.1746 - mae: 0.3201 - val_loss: 0.1675 - val_mae: 0.2857 - 121ms/epoch - 3ms/step\n",
            "Epoch 38/50\n",
            "39/39 - 0s - loss: 0.1717 - mae: 0.3201 - val_loss: 0.1505 - val_mae: 0.2854 - 143ms/epoch - 4ms/step\n",
            "Epoch 39/50\n",
            "39/39 - 0s - loss: 0.1762 - mae: 0.3228 - val_loss: 0.1573 - val_mae: 0.3284 - 111ms/epoch - 3ms/step\n",
            "Epoch 40/50\n",
            "39/39 - 0s - loss: 0.1758 - mae: 0.3233 - val_loss: 0.2846 - val_mae: 0.3923 - 103ms/epoch - 3ms/step\n",
            "Epoch 41/50\n",
            "39/39 - 0s - loss: 0.1744 - mae: 0.3265 - val_loss: 0.1643 - val_mae: 0.3454 - 110ms/epoch - 3ms/step\n",
            "Epoch 42/50\n",
            "39/39 - 0s - loss: 0.1701 - mae: 0.3187 - val_loss: 0.4068 - val_mae: 0.5001 - 110ms/epoch - 3ms/step\n",
            "Epoch 43/50\n",
            "39/39 - 0s - loss: 0.1747 - mae: 0.3224 - val_loss: 0.1604 - val_mae: 0.2777 - 98ms/epoch - 3ms/step\n",
            "Epoch 44/50\n",
            "39/39 - 0s - loss: 0.1693 - mae: 0.3173 - val_loss: 0.1544 - val_mae: 0.2831 - 102ms/epoch - 3ms/step\n",
            "Epoch 45/50\n",
            "39/39 - 0s - loss: 0.1715 - mae: 0.3198 - val_loss: 0.1493 - val_mae: 0.2993 - 102ms/epoch - 3ms/step\n",
            "Epoch 46/50\n",
            "39/39 - 0s - loss: 0.1660 - mae: 0.3149 - val_loss: 0.3276 - val_mae: 0.4337 - 100ms/epoch - 3ms/step\n",
            "Epoch 47/50\n",
            "39/39 - 0s - loss: 0.1742 - mae: 0.3229 - val_loss: 0.2536 - val_mae: 0.3640 - 99ms/epoch - 3ms/step\n",
            "Epoch 48/50\n",
            "39/39 - 0s - loss: 0.1651 - mae: 0.3127 - val_loss: 0.2953 - val_mae: 0.4038 - 109ms/epoch - 3ms/step\n",
            "Epoch 49/50\n",
            "39/39 - 0s - loss: 0.1671 - mae: 0.3142 - val_loss: 0.2148 - val_mae: 0.3229 - 95ms/epoch - 2ms/step\n",
            "Epoch 50/50\n",
            "39/39 - 0s - loss: 0.1632 - mae: 0.3090 - val_loss: 0.2511 - val_mae: 0.4518 - 103ms/epoch - 3ms/step\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_30 (Dense)            (None, 20)                260       \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 15)                315       \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 10)                160       \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 746\n",
            "Trainable params: 746\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot of Regression Model 3"
      ],
      "metadata": {
        "id": "5X_pauZJDEVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the validation and training loss\n",
        "plt.plot(range(1, len(history_regmodl3.history['val_loss']) + 1), history_regmodl3.history['val_loss'], 'go',label = \"Validation Loss\")\n",
        "plt.plot(range(1, len(history_regmodl3.history['loss']) + 1), history_regmodl3.history['loss'],label = \"Training Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# Final Values\n",
        "print(\"Final Training loss: \",history_regmodl3.history['loss'][-1],\"\\nFinal Training MAE: \", history_regmodl3.history['mae'][-1])\n",
        "print(\"Final Validation loss: \",history_regmodl3.history['val_loss'][-1],\"\\nFinal Validation MAE: \", history_regmodl3.history['val_mae'][-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hJu45xT_DHDI",
        "outputId": "b3e992c6-3cf8-4b98-f2ab-20171772c5a2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Training loss:  0.16316790878772736 \n",
            "Final Training MAE:  0.3089996576309204\n",
            "Final Validation loss:  0.2511488199234009 \n",
            "Final Validation MAE:  0.45180341601371765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_mYEn4tBe9ba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicting the Output"
      ],
      "metadata": {
        "id": "V1AScrxpmzOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_labels = np.around(regmodl3.predict(Xtst))\n",
        "predict_labels_T=predict_labels.T\n",
        "error = tst_labels - predict_labels_T\n",
        "predict_table = pd.DataFrame(Xtst)\n",
        "predict_table['activation'] = predict_labels\n",
        "predict_table['target'] = tst_labels.T\n",
        "predict_table['error'] = error.T\n",
        "# Renaming the columns of the table\n",
        "predict_table.columns.values[0] = \"f1\"\n",
        "predict_table.columns.values[1] = \"f2\"\n",
        "predict_table.columns.values[2] = \"f3\"\n",
        "predict_table.columns.values[3] = \"f4\"\n",
        "predict_table.columns.values[4] = \"f5\"\n",
        "predict_table.columns.values[5] = \"f6\"\n",
        "predict_table.columns.values[6] = \"f7\"\n",
        "predict_table.columns.values[7] = \"f8\"\n",
        "predict_table.columns.values[8] = \"f9\"\n",
        "predict_table.columns.values[9] = \"f10\"\n",
        "predict_table.columns.values[10] = \"f11\"\n",
        "predict_table.columns.values[11] = \"f12\"\n",
        "display(predict_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Ew9m2ndWm8x0",
        "outputId": "43392a7a-6796-4720-b986-19515bec3adb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa7674164d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f7081dfd-8b49-47df-b690-3139ba914630\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1</th>\n",
              "      <th>f2</th>\n",
              "      <th>f3</th>\n",
              "      <th>f4</th>\n",
              "      <th>f5</th>\n",
              "      <th>f6</th>\n",
              "      <th>f7</th>\n",
              "      <th>f8</th>\n",
              "      <th>f9</th>\n",
              "      <th>f10</th>\n",
              "      <th>f11</th>\n",
              "      <th>f12</th>\n",
              "      <th>activation</th>\n",
              "      <th>target</th>\n",
              "      <th>error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.20</td>\n",
              "      <td>11.5</td>\n",
              "      <td>0.049</td>\n",
              "      <td>44.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>0.99800</td>\n",
              "      <td>3.27</td>\n",
              "      <td>0.44</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.5</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.36</td>\n",
              "      <td>16.3</td>\n",
              "      <td>0.038</td>\n",
              "      <td>43.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>0.99924</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.41</td>\n",
              "      <td>8.800000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.6</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.24</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.034</td>\n",
              "      <td>10.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>0.98815</td>\n",
              "      <td>3.32</td>\n",
              "      <td>0.50</td>\n",
              "      <td>13.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.4</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.08</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0.045</td>\n",
              "      <td>19.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>0.99490</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.49</td>\n",
              "      <td>11.400000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.8</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.37</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.055</td>\n",
              "      <td>47.0</td>\n",
              "      <td>154.0</td>\n",
              "      <td>0.99340</td>\n",
              "      <td>3.08</td>\n",
              "      <td>0.45</td>\n",
              "      <td>9.100000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6.9</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.33</td>\n",
              "      <td>10.1</td>\n",
              "      <td>0.043</td>\n",
              "      <td>28.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>0.99680</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.52</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.33</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0.027</td>\n",
              "      <td>35.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>0.98945</td>\n",
              "      <td>3.37</td>\n",
              "      <td>0.42</td>\n",
              "      <td>12.700000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.41</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.036</td>\n",
              "      <td>42.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>0.99018</td>\n",
              "      <td>3.04</td>\n",
              "      <td>0.64</td>\n",
              "      <td>11.733333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7.3</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.32</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0.062</td>\n",
              "      <td>31.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.99728</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.65</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.22</td>\n",
              "      <td>10.7</td>\n",
              "      <td>0.042</td>\n",
              "      <td>26.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0.99540</td>\n",
              "      <td>2.86</td>\n",
              "      <td>0.36</td>\n",
              "      <td>9.700000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7081dfd-8b49-47df-b690-3139ba914630')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f7081dfd-8b49-47df-b690-3139ba914630 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f7081dfd-8b49-47df-b690-3139ba914630');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    f1    f2    f3    f4     f5  ...        f11  f12  activation  target  error\n",
              "0  7.4  0.44  0.20  11.5  0.049  ...   9.000000  0.0         3.0       2   -1.0\n",
              "1  6.5  0.23  0.36  16.3  0.038  ...   8.800000  0.0         2.0       2    0.0\n",
              "2  5.6  0.41  0.24   1.9  0.034  ...  13.500000  0.0         2.0       3    1.0\n",
              "3  6.4  0.67  0.08   2.1  0.045  ...  11.400000  1.0         2.0       2    0.0\n",
              "4  6.8  0.18  0.37   1.6  0.055  ...   9.100000  0.0         2.0       2    0.0\n",
              "5  6.9  0.41  0.33  10.1  0.043  ...   9.400000  0.0         2.0       2    0.0\n",
              "6  5.9  0.32  0.33   2.1  0.027  ...  12.700000  0.0         3.0       2   -1.0\n",
              "7  6.0  0.24  0.41   1.3  0.036  ...  11.733333  0.0         3.0       2   -1.0\n",
              "8  7.3  0.48  0.32   2.1  0.062  ...  10.000000  1.0         2.0       3    1.0\n",
              "9  7.4  0.24  0.22  10.7  0.042  ...   9.700000  0.0         2.0       2    0.0\n",
              "\n",
              "[10 rows x 15 columns]"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}